{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Service Titan Data Science Internship",
   "id": "2a958d22455b8020"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importing necessary libraries.",
   "id": "319be7ca76dd89c2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:52.506510Z",
     "start_time": "2024-06-07T11:01:52.503487Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Rules for Conversion Table and Expiration.",
   "id": "5441473f37bdbe9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:53.164537Z",
     "start_time": "2024-06-07T11:01:53.161790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv_table = {\n",
    "    0: 'Material',\n",
    "    1: 'Equipment',\n",
    "    2: 'Service',\n",
    "    3: 'Other'\n",
    "}\n",
    "exp = [305869, 377307, 391273, 385290, 331902, 397723, 343695, 340601, 347510, 325156, 379387, 348894, 322229, 326649, 377960, 325063, 369378, 319405, 383681, 367288, 356552, 394428, 381476, 381457, 349879, 343254, 366751, 330931, 363263, 326452, 379687, 356532, 383235, 313012, 368913, 352442, 315960, 351096, 331193, 392657, 352391, 389528, 338547, 379961, 337140, 323231, 371205, 378746, 307175, 340299]"
   ],
   "id": "2f047d423ff786c1",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Data Extractor Class.",
   "id": "b21fefe620ac0a1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:53.807731Z",
     "start_time": "2024-06-07T11:01:53.801232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataExtractor:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.df = None\n",
    "        self.data = None\n",
    "        \n",
    "    # Reading data\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            self.data = pd.read_pickle(self.path)\n",
    "            print(\"Data loaded\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found\")\n",
    "            \n",
    "    def create_dataframe(self):\n",
    "        #Creating Empty DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        #Creating Empty lists for each column of the Data Frame.\n",
    "        invoice_id = []\n",
    "        created_on = []\n",
    "        invoiceitem_id = []\n",
    "        invoiceitem_name = []\n",
    "        type = []\n",
    "        unit_price = []\n",
    "        quantity = []\n",
    "        \n",
    "        #As in some places there is no value corresponding to key 'items' we need to remove them to be able to work.\n",
    "        for i in self.data:\n",
    "            if i.get('items'):\n",
    "                pass\n",
    "            else:\n",
    "                self.data.remove(i)\n",
    "        #Using a nested loop to fill the empty lists.\n",
    "        for i in self.data:\n",
    "            for j in i['items']:\n",
    "                invoice_id.append(i['id']) #As we have more than 1 item corresponding to each invoice id we need to have repeating ids.\n",
    "                created_on.append(i['created_on']) #The same for created one\n",
    "                invoiceitem_id.append(j['item']['id'])\n",
    "                invoiceitem_name.append(j['item']['name'])\n",
    "                type.append(j['item']['type'])\n",
    "                unit_price.append(j['item']['unit_price'])\n",
    "                quantity.append(j['quantity'])\n",
    "                \n",
    "        #Asingn the lists to columns of the empty Data Frame.\n",
    "        df['invoice_id'] = invoice_id\n",
    "        df['created_on'] = created_on\n",
    "        df['invoiceitem_id'] = invoiceitem_id\n",
    "        df['invoiceitem_name'] = invoiceitem_name\n",
    "        df['type'] = type\n",
    "        df['unit_price'] = unit_price\n",
    "        df['quantity'] = quantity\n",
    "        \n",
    "        #As all ID values are 6-digit numbers there are some IDs that have 6 digits and a letter 'O' at the end, we need to deal with it as well. After it we can convert it to type int.\n",
    "        df['invoice_id'] = df['invoice_id'].astype(str) #first we need to convert it to str for str.rstrip to work\n",
    "        df['invoice_id'] = df['invoice_id'].str.rstrip('O')\n",
    "        df['invoice_id'] = df['invoice_id'].astype(int)\n",
    "        \n",
    "        #As there is a February 30th date in our created on column we cannot convert it to datetime type, that is why the most resonable solution would be simply deleting that kind of rows.\n",
    "        df = df[df['created_on'] != '2019-02-30']\n",
    "        df.reset_index(drop=True, inplace=True) #Resetting index to avoid further issues.\n",
    "        df['created_on'] = pd.to_datetime(df['created_on'])\n",
    "        \n",
    "        #Doing further data type assignments.\n",
    "        df['invoiceitem_name'] = df['invoiceitem_name'].astype(str)\n",
    "        df['invoiceitem_id'] = df['invoiceitem_id'].astype(int)\n",
    "        df['unit_price'] = df['unit_price'].astype(int)\n",
    "        \n",
    "        #Mapping the type column with the given conversion table.\n",
    "        df['type'] = df['type'].map(conv_table)\n",
    "        \n",
    "        #As in the quantity column there were too many issues, for example there were negative values or string values, the most resonable solution would be deleting that rows. Here we are filling the errors with NaN and further dropping them.\n",
    "        df['quantity'] = df['quantity'].apply(pd.to_numeric, errors='coerce')\n",
    "        df.dropna(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df['quantity'] = df['quantity'].astype(int)\n",
    "        \n",
    "        #Creating the total price column with the given rule.\n",
    "        df['total_price'] = df['unit_price'] * df['quantity']\n",
    "        df['total_price'] = df['total_price'].astype(int)\n",
    "        \n",
    "        #Creating the percentage in invoice column with the given rule.\n",
    "        df['invoice_total'] = df.groupby('invoice_id')['total_price'].transform('sum')\n",
    "        df['percentage_in_invoice'] = df['unit_price'] * df['quantity'] / df['invoice_total']\n",
    "        \n",
    "        #Creating the expired coulmn with the given rule.\n",
    "        df['is_expired']= df['invoice_id']\n",
    "        df['is_expired'] = df['is_expired'].apply(lambda x: x in exp)\n",
    "        \n",
    "        #Dropping Unnecessary Columns.\n",
    "        df.drop(['quantity', 'invoice_total'], axis=1, inplace=True)\n",
    "        self.df = df\n",
    "        print('Data Frame created')\n",
    "        \n",
    "    def sort_data(self):\n",
    "        self.df = self.df.sort_values(by=['invoice_id', 'invoiceitem_id'])\n",
    "        print('Data sorted')\n",
    "        \n",
    "    def export_csv(self, export_path):\n",
    "        self.df.to_csv(export_path, index=False)\n",
    "        print('Data exported')         "
   ],
   "id": "f54c96af3001f94f",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:54.329025Z",
     "start_time": "2024-06-07T11:01:54.326400Z"
    }
   },
   "cell_type": "code",
   "source": "ext = DataExtractor('invoices_new.pkl')",
   "id": "778b48dda5e96110",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:54.770611Z",
     "start_time": "2024-06-07T11:01:54.767327Z"
    }
   },
   "cell_type": "code",
   "source": "ext.load_data()",
   "id": "7067a424f635d455",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:55.117429Z",
     "start_time": "2024-06-07T11:01:55.108157Z"
    }
   },
   "cell_type": "code",
   "source": "ext.create_dataframe()",
   "id": "4ee608730acaaf8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame created\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:55.481737Z",
     "start_time": "2024-06-07T11:01:55.478263Z"
    }
   },
   "cell_type": "code",
   "source": "ext.sort_data()",
   "id": "9fd755226fe074b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sorted\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T11:01:56.002750Z",
     "start_time": "2024-06-07T11:01:55.998739Z"
    }
   },
   "cell_type": "code",
   "source": "ext.export_csv('result.csv')",
   "id": "bbee2f5b90f78414",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported\n"
     ]
    }
   ],
   "execution_count": 66
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
